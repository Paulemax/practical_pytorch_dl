{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31822bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b768e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccd13ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "model = ...\n",
    "# on GPU\n",
    "#model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ec4cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dataset\n",
    "ds_train = ...\n",
    "ds_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06ee355d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'ellipsis' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_90284/3949138132.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#define dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdl_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdl_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m     99\u001b[0m                              \"since a random permute will be performed.\")\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[1;32m    103\u001b[0m                              \"value, but got num_samples={}\".format(self.num_samples))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36mnum_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# dataset size might change at runtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'ellipsis' has no len()"
     ]
    }
   ],
   "source": [
    "#define dataloader\n",
    "dl_train = DataLoader(ds_train, shuffle=True, batch_size=bs,  drop_last=True)\n",
    "dl_test = DataLoader(ds_test, shuffle=False, batch_size=bs,  drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2f4590a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = #nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0ceaaee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "print_loss_every_n_iterations = 1\n",
    "total_iterations = epochs * len(dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "25639634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 410 with a loss of: 6681.37939453125\n",
      "Iteration 2 of 410 with a loss of: 8463.94140625\n",
      "Iteration 3 of 410 with a loss of: 6357.0869140625\n",
      "Iteration 4 of 410 with a loss of: 3356.358642578125\n",
      "Iteration 5 of 410 with a loss of: 11282.5869140625\n",
      "Iteration 6 of 410 with a loss of: 6274.68798828125\n",
      "Iteration 7 of 410 with a loss of: 7839.986328125\n",
      "Iteration 8 of 410 with a loss of: 5692.47705078125\n",
      "Iteration 9 of 410 with a loss of: 9442.1513671875\n",
      "Iteration 10 of 410 with a loss of: 7492.916015625\n",
      "Iteration 11 of 410 with a loss of: 4011.9150390625\n",
      "Iteration 12 of 410 with a loss of: 4765.67041015625\n",
      "Iteration 13 of 410 with a loss of: 8279.265625\n",
      "Iteration 14 of 410 with a loss of: 2870.4384765625\n",
      "Iteration 15 of 410 with a loss of: 6181.39013671875\n",
      "Iteration 16 of 410 with a loss of: 7104.87060546875\n",
      "Iteration 17 of 410 with a loss of: 6168.3525390625\n",
      "Iteration 18 of 410 with a loss of: 8288.2568359375\n",
      "Iteration 19 of 410 with a loss of: 6529.6728515625\n",
      "Iteration 20 of 410 with a loss of: 7801.681640625\n",
      "Iteration 21 of 410 with a loss of: 5885.94970703125\n",
      "Iteration 22 of 410 with a loss of: 3123.770751953125\n",
      "Iteration 23 of 410 with a loss of: 13955.8310546875\n",
      "Iteration 24 of 410 with a loss of: 6216.42041015625\n",
      "Iteration 25 of 410 with a loss of: 2219.801025390625\n",
      "Iteration 26 of 410 with a loss of: 6563.47802734375\n",
      "Iteration 27 of 410 with a loss of: 6499.29736328125\n",
      "Iteration 28 of 410 with a loss of: 4946.70849609375\n",
      "Iteration 29 of 410 with a loss of: 9955.3828125\n",
      "Iteration 30 of 410 with a loss of: 7581.85302734375\n",
      "Iteration 31 of 410 with a loss of: 4960.57275390625\n",
      "Iteration 32 of 410 with a loss of: 6083.6376953125\n",
      "Iteration 33 of 410 with a loss of: 6447.49658203125\n",
      "Iteration 34 of 410 with a loss of: 5135.48876953125\n",
      "Iteration 35 of 410 with a loss of: 5267.8798828125\n",
      "Iteration 36 of 410 with a loss of: 5145.7119140625\n",
      "Iteration 37 of 410 with a loss of: 5896.751953125\n",
      "Iteration 38 of 410 with a loss of: 8425.232421875\n",
      "Iteration 39 of 410 with a loss of: 6991.8017578125\n",
      "Iteration 40 of 410 with a loss of: 4484.16552734375\n",
      "Iteration 41 of 410 with a loss of: 3539.385986328125\n",
      "Iteration 42 of 410 with a loss of: 10890.822265625\n",
      "Iteration 43 of 410 with a loss of: 9198.0341796875\n",
      "Iteration 44 of 410 with a loss of: 7792.240234375\n",
      "Iteration 45 of 410 with a loss of: 8102.037109375\n",
      "Iteration 46 of 410 with a loss of: 6805.09716796875\n",
      "Iteration 47 of 410 with a loss of: 6905.51513671875\n",
      "Iteration 48 of 410 with a loss of: 8709.2490234375\n",
      "Iteration 49 of 410 with a loss of: 6877.4814453125\n",
      "Iteration 50 of 410 with a loss of: 6457.0400390625\n",
      "Iteration 51 of 410 with a loss of: 4250.2373046875\n",
      "Iteration 52 of 410 with a loss of: 7571.41845703125\n",
      "Iteration 53 of 410 with a loss of: 7931.5107421875\n",
      "Iteration 54 of 410 with a loss of: 7558.98876953125\n",
      "Iteration 55 of 410 with a loss of: 7491.94091796875\n",
      "Iteration 56 of 410 with a loss of: 8344.8056640625\n",
      "Iteration 57 of 410 with a loss of: 6960.9609375\n",
      "Iteration 58 of 410 with a loss of: 6459.3515625\n",
      "Iteration 59 of 410 with a loss of: 6259.75537109375\n",
      "Iteration 60 of 410 with a loss of: 6681.99462890625\n",
      "Iteration 61 of 410 with a loss of: 6801.9462890625\n",
      "Iteration 62 of 410 with a loss of: 5406.6513671875\n",
      "Iteration 63 of 410 with a loss of: 7414.033203125\n",
      "Iteration 64 of 410 with a loss of: 6262.3671875\n",
      "Iteration 65 of 410 with a loss of: 5179.791015625\n",
      "Iteration 66 of 410 with a loss of: 7700.33984375\n",
      "Iteration 67 of 410 with a loss of: 3330.827880859375\n",
      "Iteration 68 of 410 with a loss of: 2424.478515625\n",
      "Iteration 69 of 410 with a loss of: 3419.66162109375\n",
      "Iteration 70 of 410 with a loss of: 6676.7138671875\n",
      "Iteration 71 of 410 with a loss of: 6480.083984375\n",
      "Iteration 72 of 410 with a loss of: 2192.512939453125\n",
      "Iteration 73 of 410 with a loss of: 9140.25390625\n",
      "Iteration 74 of 410 with a loss of: 2895.767578125\n",
      "Iteration 75 of 410 with a loss of: 1730.254638671875\n",
      "Iteration 76 of 410 with a loss of: 5536.2705078125\n",
      "Iteration 77 of 410 with a loss of: 4674.27392578125\n",
      "Iteration 78 of 410 with a loss of: 3861.75390625\n",
      "Iteration 79 of 410 with a loss of: 7878.12890625\n",
      "Iteration 80 of 410 with a loss of: 4204.65625\n",
      "Iteration 81 of 410 with a loss of: 3049.451171875\n",
      "Iteration 82 of 410 with a loss of: 7939.869140625\n",
      "Iteration 83 of 410 with a loss of: 4899.25341796875\n",
      "Iteration 84 of 410 with a loss of: 4161.42041015625\n",
      "Iteration 85 of 410 with a loss of: 7125.1533203125\n",
      "Iteration 86 of 410 with a loss of: 3679.7900390625\n",
      "Iteration 87 of 410 with a loss of: 5078.90673828125\n",
      "Iteration 88 of 410 with a loss of: 8443.826171875\n",
      "Iteration 89 of 410 with a loss of: 7298.6474609375\n",
      "Iteration 90 of 410 with a loss of: 8654.10546875\n",
      "Iteration 91 of 410 with a loss of: 8636.2470703125\n",
      "Iteration 92 of 410 with a loss of: 7615.91650390625\n",
      "Iteration 93 of 410 with a loss of: 6762.2880859375\n",
      "Iteration 94 of 410 with a loss of: 8068.03662109375\n",
      "Iteration 95 of 410 with a loss of: 7256.8134765625\n",
      "Iteration 96 of 410 with a loss of: 6210.89501953125\n",
      "Iteration 97 of 410 with a loss of: 4777.37451171875\n",
      "Iteration 98 of 410 with a loss of: 5069.974609375\n",
      "Iteration 99 of 410 with a loss of: 7565.0341796875\n",
      "Iteration 100 of 410 with a loss of: 6660.53857421875\n",
      "Iteration 101 of 410 with a loss of: 5297.0126953125\n",
      "Iteration 102 of 410 with a loss of: 6037.7265625\n",
      "Iteration 103 of 410 with a loss of: 6879.5205078125\n",
      "Iteration 104 of 410 with a loss of: 4584.34130859375\n",
      "Iteration 105 of 410 with a loss of: 7342.86669921875\n",
      "Iteration 106 of 410 with a loss of: 4845.59765625\n",
      "Iteration 107 of 410 with a loss of: 6649.45849609375\n",
      "Iteration 108 of 410 with a loss of: 8162.32763671875\n",
      "Iteration 109 of 410 with a loss of: 4553.5927734375\n",
      "Iteration 110 of 410 with a loss of: 2884.27490234375\n",
      "Iteration 111 of 410 with a loss of: 6644.36376953125\n",
      "Iteration 112 of 410 with a loss of: 3302.547119140625\n",
      "Iteration 113 of 410 with a loss of: 6014.65673828125\n",
      "Iteration 114 of 410 with a loss of: 7406.34814453125\n",
      "Iteration 115 of 410 with a loss of: 3761.566162109375\n",
      "Iteration 116 of 410 with a loss of: 3088.126708984375\n",
      "Iteration 117 of 410 with a loss of: 9992.275390625\n",
      "Iteration 118 of 410 with a loss of: 6394.72509765625\n",
      "Iteration 119 of 410 with a loss of: 5435.95654296875\n",
      "Iteration 120 of 410 with a loss of: 5474.53955078125\n",
      "Iteration 121 of 410 with a loss of: 4373.8798828125\n",
      "Iteration 122 of 410 with a loss of: 7627.91259765625\n",
      "Iteration 123 of 410 with a loss of: 9013.240234375\n",
      "Iteration 124 of 410 with a loss of: 9161.7607421875\n",
      "Iteration 125 of 410 with a loss of: 4590.5458984375\n",
      "Iteration 126 of 410 with a loss of: 4857.1083984375\n",
      "Iteration 127 of 410 with a loss of: 12463.140625\n",
      "Iteration 128 of 410 with a loss of: 6331.7880859375\n",
      "Iteration 129 of 410 with a loss of: 5885.96337890625\n",
      "Iteration 130 of 410 with a loss of: 4257.443359375\n",
      "Iteration 131 of 410 with a loss of: 4654.54248046875\n",
      "Iteration 132 of 410 with a loss of: 7100.04638671875\n",
      "Iteration 133 of 410 with a loss of: 6342.86181640625\n",
      "Iteration 134 of 410 with a loss of: 8681.630859375\n",
      "Iteration 135 of 410 with a loss of: 5806.04296875\n",
      "Iteration 136 of 410 with a loss of: 9456.6259765625\n",
      "Iteration 137 of 410 with a loss of: 6940.59326171875\n",
      "Iteration 138 of 410 with a loss of: 9698.7431640625\n",
      "Iteration 139 of 410 with a loss of: 6376.15087890625\n",
      "Iteration 140 of 410 with a loss of: 4395.95556640625\n",
      "Iteration 141 of 410 with a loss of: 5940.48291015625\n",
      "Iteration 142 of 410 with a loss of: 7474.4736328125\n",
      "Iteration 143 of 410 with a loss of: 6953.90673828125\n",
      "Iteration 144 of 410 with a loss of: 5735.3837890625\n",
      "Iteration 145 of 410 with a loss of: 7522.87353515625\n",
      "Iteration 146 of 410 with a loss of: 3072.542236328125\n",
      "Iteration 147 of 410 with a loss of: 9830.1015625\n",
      "Iteration 148 of 410 with a loss of: 4045.96435546875\n",
      "Iteration 149 of 410 with a loss of: 8425.3603515625\n",
      "Iteration 150 of 410 with a loss of: 5389.69287109375\n",
      "Iteration 151 of 410 with a loss of: 3341.755615234375\n",
      "Iteration 152 of 410 with a loss of: 7842.5615234375\n",
      "Iteration 153 of 410 with a loss of: 5730.82080078125\n",
      "Iteration 154 of 410 with a loss of: 3507.74365234375\n",
      "Iteration 155 of 410 with a loss of: 8880.5498046875\n",
      "Iteration 156 of 410 with a loss of: 6020.9208984375\n",
      "Iteration 157 of 410 with a loss of: 5524.8349609375\n",
      "Iteration 158 of 410 with a loss of: 7217.9697265625\n",
      "Iteration 159 of 410 with a loss of: 3932.1572265625\n",
      "Iteration 160 of 410 with a loss of: 6697.15869140625\n",
      "Iteration 161 of 410 with a loss of: 3087.722412109375\n",
      "Iteration 162 of 410 with a loss of: 4338.373046875\n",
      "Iteration 163 of 410 with a loss of: 2711.19873046875\n",
      "Iteration 164 of 410 with a loss of: 8239.310546875\n",
      "Iteration 165 of 410 with a loss of: 5183.0185546875\n",
      "Iteration 166 of 410 with a loss of: 3763.700439453125\n",
      "Iteration 167 of 410 with a loss of: 11566.943359375\n",
      "Iteration 168 of 410 with a loss of: 3906.08740234375\n",
      "Iteration 169 of 410 with a loss of: 4267.70556640625\n",
      "Iteration 170 of 410 with a loss of: 6385.65478515625\n",
      "Iteration 171 of 410 with a loss of: 5887.4794921875\n",
      "Iteration 172 of 410 with a loss of: 6069.0771484375\n",
      "Iteration 173 of 410 with a loss of: 12883.7421875\n",
      "Iteration 174 of 410 with a loss of: 7705.26904296875\n",
      "Iteration 175 of 410 with a loss of: 7253.6240234375\n",
      "Iteration 176 of 410 with a loss of: 4943.8310546875\n",
      "Iteration 177 of 410 with a loss of: 2753.556884765625\n",
      "Iteration 178 of 410 with a loss of: 5127.3984375\n",
      "Iteration 179 of 410 with a loss of: 6706.685546875\n",
      "Iteration 180 of 410 with a loss of: 6857.65771484375\n",
      "Iteration 181 of 410 with a loss of: 7695.12109375\n",
      "Iteration 182 of 410 with a loss of: 9496.6591796875\n",
      "Iteration 183 of 410 with a loss of: 6705.38671875\n",
      "Iteration 184 of 410 with a loss of: 8866.197265625\n",
      "Iteration 185 of 410 with a loss of: 4042.764892578125\n",
      "Iteration 186 of 410 with a loss of: 7148.447265625\n",
      "Iteration 187 of 410 with a loss of: 6249.7119140625\n",
      "Iteration 188 of 410 with a loss of: 5176.00732421875\n",
      "Iteration 189 of 410 with a loss of: 3863.25537109375\n",
      "Iteration 190 of 410 with a loss of: 6197.9189453125\n",
      "Iteration 191 of 410 with a loss of: 4519.31787109375\n",
      "Iteration 192 of 410 with a loss of: 5851.7060546875\n",
      "Iteration 193 of 410 with a loss of: 3931.634033203125\n",
      "Iteration 194 of 410 with a loss of: 5159.2919921875\n",
      "Iteration 195 of 410 with a loss of: 4358.17529296875\n",
      "Iteration 196 of 410 with a loss of: 10057.412109375\n",
      "Iteration 197 of 410 with a loss of: 2857.56982421875\n",
      "Iteration 198 of 410 with a loss of: 8496.9873046875\n",
      "Iteration 199 of 410 with a loss of: 3301.10302734375\n",
      "Iteration 200 of 410 with a loss of: 6893.3486328125\n",
      "Iteration 201 of 410 with a loss of: 9412.3203125\n",
      "Iteration 202 of 410 with a loss of: 3361.992919921875\n",
      "Iteration 203 of 410 with a loss of: 7656.42919921875\n",
      "Iteration 204 of 410 with a loss of: 4195.4541015625\n",
      "Iteration 205 of 410 with a loss of: 7592.53173828125\n",
      "Iteration 206 of 410 with a loss of: 5302.099609375\n",
      "Iteration 207 of 410 with a loss of: 5174.310546875\n",
      "Iteration 208 of 410 with a loss of: 8482.3427734375\n",
      "Iteration 209 of 410 with a loss of: 9181.3544921875\n",
      "Iteration 210 of 410 with a loss of: 14353.361328125\n",
      "Iteration 211 of 410 with a loss of: 3423.4736328125\n",
      "Iteration 212 of 410 with a loss of: 5100.8427734375\n",
      "Iteration 213 of 410 with a loss of: 6853.45166015625\n",
      "Iteration 214 of 410 with a loss of: 8355.0068359375\n",
      "Iteration 215 of 410 with a loss of: 8816.6474609375\n",
      "Iteration 216 of 410 with a loss of: 4621.93896484375\n",
      "Iteration 217 of 410 with a loss of: 4539.85546875\n",
      "Iteration 218 of 410 with a loss of: 4203.91943359375\n",
      "Iteration 219 of 410 with a loss of: 6130.26904296875\n",
      "Iteration 220 of 410 with a loss of: 7114.0712890625\n",
      "Iteration 221 of 410 with a loss of: 8463.6064453125\n",
      "Iteration 222 of 410 with a loss of: 5137.30712890625\n",
      "Iteration 223 of 410 with a loss of: 7052.40869140625\n",
      "Iteration 224 of 410 with a loss of: 4365.37158203125\n",
      "Iteration 225 of 410 with a loss of: 9185.4619140625\n",
      "Iteration 226 of 410 with a loss of: 4850.20263671875\n",
      "Iteration 227 of 410 with a loss of: 8980.974609375\n",
      "Iteration 228 of 410 with a loss of: 9633.31640625\n",
      "Iteration 229 of 410 with a loss of: 5185.759765625\n",
      "Iteration 230 of 410 with a loss of: 6943.74560546875\n",
      "Iteration 231 of 410 with a loss of: 7148.2763671875\n",
      "Iteration 232 of 410 with a loss of: 4090.791015625\n",
      "Iteration 233 of 410 with a loss of: 4652.80126953125\n",
      "Iteration 234 of 410 with a loss of: 5231.927734375\n",
      "Iteration 235 of 410 with a loss of: 9517.443359375\n",
      "Iteration 236 of 410 with a loss of: 10073.634765625\n",
      "Iteration 237 of 410 with a loss of: 4700.18701171875\n",
      "Iteration 238 of 410 with a loss of: 6741.89111328125\n",
      "Iteration 239 of 410 with a loss of: 6199.6884765625\n",
      "Iteration 240 of 410 with a loss of: 5820.095703125\n",
      "Iteration 241 of 410 with a loss of: 6005.05859375\n",
      "Iteration 242 of 410 with a loss of: 5423.26806640625\n",
      "Iteration 243 of 410 with a loss of: 6692.42724609375\n",
      "Iteration 244 of 410 with a loss of: 4079.87158203125\n",
      "Iteration 245 of 410 with a loss of: 6974.6875\n",
      "Iteration 246 of 410 with a loss of: 5078.125\n",
      "Iteration 247 of 410 with a loss of: 4217.0576171875\n",
      "Iteration 248 of 410 with a loss of: 4313.89990234375\n",
      "Iteration 249 of 410 with a loss of: 8484.2587890625\n",
      "Iteration 250 of 410 with a loss of: 8394.248046875\n",
      "Iteration 251 of 410 with a loss of: 3216.4384765625\n",
      "Iteration 252 of 410 with a loss of: 5620.56103515625\n",
      "Iteration 253 of 410 with a loss of: 7559.5986328125\n",
      "Iteration 254 of 410 with a loss of: 9219.2724609375\n",
      "Iteration 255 of 410 with a loss of: 2976.463134765625\n",
      "Iteration 256 of 410 with a loss of: 9064.08203125\n",
      "Iteration 257 of 410 with a loss of: 2516.56884765625\n",
      "Iteration 258 of 410 with a loss of: 4488.3203125\n",
      "Iteration 259 of 410 with a loss of: 3856.30859375\n",
      "Iteration 260 of 410 with a loss of: 2491.742431640625\n",
      "Iteration 261 of 410 with a loss of: 6099.90771484375\n",
      "Iteration 262 of 410 with a loss of: 5675.9970703125\n",
      "Iteration 263 of 410 with a loss of: 8363.8173828125\n",
      "Iteration 264 of 410 with a loss of: 5058.12060546875\n",
      "Iteration 265 of 410 with a loss of: 7129.35546875\n",
      "Iteration 266 of 410 with a loss of: 6335.64208984375\n",
      "Iteration 267 of 410 with a loss of: 8852.6650390625\n",
      "Iteration 268 of 410 with a loss of: 5976.4970703125\n",
      "Iteration 269 of 410 with a loss of: 4826.4482421875\n",
      "Iteration 270 of 410 with a loss of: 7345.3291015625\n",
      "Iteration 271 of 410 with a loss of: 6910.201171875\n",
      "Iteration 272 of 410 with a loss of: 3511.33935546875\n",
      "Iteration 273 of 410 with a loss of: 9144.4736328125\n",
      "Iteration 274 of 410 with a loss of: 4775.21484375\n",
      "Iteration 275 of 410 with a loss of: 5638.97265625\n",
      "Iteration 276 of 410 with a loss of: 5994.455078125\n",
      "Iteration 277 of 410 with a loss of: 2937.27978515625\n",
      "Iteration 278 of 410 with a loss of: 5340.3203125\n",
      "Iteration 279 of 410 with a loss of: 10627.5361328125\n",
      "Iteration 280 of 410 with a loss of: 5429.80615234375\n",
      "Iteration 281 of 410 with a loss of: 5901.142578125\n",
      "Iteration 282 of 410 with a loss of: 11656.08984375\n",
      "Iteration 283 of 410 with a loss of: 7698.4609375\n",
      "Iteration 284 of 410 with a loss of: 9067.384765625\n",
      "Iteration 285 of 410 with a loss of: 5697.42041015625\n",
      "Iteration 286 of 410 with a loss of: 2911.13916015625\n",
      "Iteration 287 of 410 with a loss of: 11263.009765625\n",
      "Iteration 288 of 410 with a loss of: 6336.86572265625\n",
      "Iteration 289 of 410 with a loss of: 5233.20849609375\n",
      "Iteration 290 of 410 with a loss of: 4842.6572265625\n",
      "Iteration 291 of 410 with a loss of: 6669.4794921875\n",
      "Iteration 292 of 410 with a loss of: 6408.40283203125\n",
      "Iteration 293 of 410 with a loss of: 8802.392578125\n",
      "Iteration 294 of 410 with a loss of: 6606.90625\n",
      "Iteration 295 of 410 with a loss of: 8033.5751953125\n",
      "Iteration 296 of 410 with a loss of: 7383.04833984375\n",
      "Iteration 297 of 410 with a loss of: 7447.693359375\n",
      "Iteration 298 of 410 with a loss of: 2373.900146484375\n",
      "Iteration 299 of 410 with a loss of: 5306.203125\n",
      "Iteration 300 of 410 with a loss of: 7133.345703125\n",
      "Iteration 301 of 410 with a loss of: 8627.6025390625\n",
      "Iteration 302 of 410 with a loss of: 7267.30615234375\n",
      "Iteration 303 of 410 with a loss of: 4209.66650390625\n",
      "Iteration 304 of 410 with a loss of: 7143.0576171875\n",
      "Iteration 305 of 410 with a loss of: 11097.98046875\n",
      "Iteration 306 of 410 with a loss of: 11686.7744140625\n",
      "Iteration 307 of 410 with a loss of: 2880.82568359375\n",
      "Iteration 308 of 410 with a loss of: 1614.9183349609375\n",
      "Iteration 309 of 410 with a loss of: 5747.00244140625\n",
      "Iteration 310 of 410 with a loss of: 5318.513671875\n",
      "Iteration 311 of 410 with a loss of: 4559.34326171875\n",
      "Iteration 312 of 410 with a loss of: 3616.6005859375\n",
      "Iteration 313 of 410 with a loss of: 3562.721923828125\n",
      "Iteration 314 of 410 with a loss of: 5605.8173828125\n",
      "Iteration 315 of 410 with a loss of: 8945.107421875\n",
      "Iteration 316 of 410 with a loss of: 8932.615234375\n",
      "Iteration 317 of 410 with a loss of: 6512.2626953125\n",
      "Iteration 318 of 410 with a loss of: 7820.6103515625\n",
      "Iteration 319 of 410 with a loss of: 10593.451171875\n",
      "Iteration 320 of 410 with a loss of: 5547.63134765625\n",
      "Iteration 321 of 410 with a loss of: 8632.74609375\n",
      "Iteration 322 of 410 with a loss of: 8107.9345703125\n",
      "Iteration 323 of 410 with a loss of: 5714.0634765625\n",
      "Iteration 324 of 410 with a loss of: 5423.99365234375\n",
      "Iteration 325 of 410 with a loss of: 7772.490234375\n",
      "Iteration 326 of 410 with a loss of: 8043.4384765625\n",
      "Iteration 327 of 410 with a loss of: 3906.947509765625\n",
      "Iteration 328 of 410 with a loss of: 4996.71435546875\n",
      "Iteration 329 of 410 with a loss of: 9176.66015625\n",
      "Iteration 330 of 410 with a loss of: 7780.6396484375\n",
      "Iteration 331 of 410 with a loss of: 2767.587890625\n",
      "Iteration 332 of 410 with a loss of: 8744.15234375\n",
      "Iteration 333 of 410 with a loss of: 7114.44580078125\n",
      "Iteration 334 of 410 with a loss of: 4807.228515625\n",
      "Iteration 335 of 410 with a loss of: 3923.590087890625\n",
      "Iteration 336 of 410 with a loss of: 2507.263671875\n",
      "Iteration 337 of 410 with a loss of: 3303.077392578125\n",
      "Iteration 338 of 410 with a loss of: 5169.62109375\n",
      "Iteration 339 of 410 with a loss of: 3809.7177734375\n",
      "Iteration 340 of 410 with a loss of: 5305.52880859375\n",
      "Iteration 341 of 410 with a loss of: 11128.3134765625\n",
      "Iteration 342 of 410 with a loss of: 5800.8984375\n",
      "Iteration 343 of 410 with a loss of: 4187.84814453125\n",
      "Iteration 344 of 410 with a loss of: 5517.1396484375\n",
      "Iteration 345 of 410 with a loss of: 9303.349609375\n",
      "Iteration 346 of 410 with a loss of: 6923.341796875\n",
      "Iteration 347 of 410 with a loss of: 6844.1552734375\n",
      "Iteration 348 of 410 with a loss of: 5260.951171875\n",
      "Iteration 349 of 410 with a loss of: 612.510498046875\n",
      "Iteration 350 of 410 with a loss of: 8152.66455078125\n",
      "Iteration 351 of 410 with a loss of: 9733.1650390625\n",
      "Iteration 352 of 410 with a loss of: 5810.9501953125\n",
      "Iteration 353 of 410 with a loss of: 6588.1123046875\n",
      "Iteration 354 of 410 with a loss of: 4761.78515625\n",
      "Iteration 355 of 410 with a loss of: 7578.431640625\n",
      "Iteration 356 of 410 with a loss of: 6258.2666015625\n",
      "Iteration 357 of 410 with a loss of: 13918.283203125\n",
      "Iteration 358 of 410 with a loss of: 3251.3203125\n",
      "Iteration 359 of 410 with a loss of: 9144.05078125\n",
      "Iteration 360 of 410 with a loss of: 2387.821044921875\n",
      "Iteration 361 of 410 with a loss of: 3891.28076171875\n",
      "Iteration 362 of 410 with a loss of: 6681.99169921875\n",
      "Iteration 363 of 410 with a loss of: 2276.238037109375\n",
      "Iteration 364 of 410 with a loss of: 7899.11962890625\n",
      "Iteration 365 of 410 with a loss of: 3836.671142578125\n",
      "Iteration 366 of 410 with a loss of: 2111.947021484375\n",
      "Iteration 367 of 410 with a loss of: 9533.6201171875\n",
      "Iteration 368 of 410 with a loss of: 6669.87353515625\n",
      "Iteration 369 of 410 with a loss of: 9434.208984375\n",
      "Iteration 370 of 410 with a loss of: 7042.369140625\n",
      "Iteration 371 of 410 with a loss of: 9241.630859375\n",
      "Iteration 372 of 410 with a loss of: 6574.5263671875\n",
      "Iteration 373 of 410 with a loss of: 8769.3427734375\n",
      "Iteration 374 of 410 with a loss of: 8995.5615234375\n",
      "Iteration 375 of 410 with a loss of: 5087.1142578125\n",
      "Iteration 376 of 410 with a loss of: 7107.68505859375\n",
      "Iteration 377 of 410 with a loss of: 5149.93359375\n",
      "Iteration 378 of 410 with a loss of: 6244.837890625\n",
      "Iteration 379 of 410 with a loss of: 4218.0400390625\n",
      "Iteration 380 of 410 with a loss of: 4727.451171875\n",
      "Iteration 381 of 410 with a loss of: 7059.2158203125\n",
      "Iteration 382 of 410 with a loss of: 5353.65185546875\n",
      "Iteration 383 of 410 with a loss of: 5120.02734375\n",
      "Iteration 384 of 410 with a loss of: 3701.006103515625\n",
      "Iteration 385 of 410 with a loss of: 3660.6337890625\n",
      "Iteration 386 of 410 with a loss of: 8152.9990234375\n",
      "Iteration 387 of 410 with a loss of: 5460.93359375\n",
      "Iteration 388 of 410 with a loss of: 2084.384765625\n",
      "Iteration 389 of 410 with a loss of: 4246.4365234375\n",
      "Iteration 390 of 410 with a loss of: 8179.45849609375\n",
      "Iteration 391 of 410 with a loss of: 6380.41650390625\n",
      "Iteration 392 of 410 with a loss of: 4300.77490234375\n",
      "Iteration 393 of 410 with a loss of: 5659.36328125\n",
      "Iteration 394 of 410 with a loss of: 3323.196533203125\n",
      "Iteration 395 of 410 with a loss of: 3924.185302734375\n",
      "Iteration 396 of 410 with a loss of: 8868.498046875\n",
      "Iteration 397 of 410 with a loss of: 8352.041015625\n",
      "Iteration 398 of 410 with a loss of: 9601.1435546875\n",
      "Iteration 399 of 410 with a loss of: 1345.62109375\n",
      "Iteration 400 of 410 with a loss of: 9181.603515625\n",
      "Iteration 401 of 410 with a loss of: 3680.767822265625\n",
      "Iteration 402 of 410 with a loss of: 3446.885009765625\n",
      "Iteration 403 of 410 with a loss of: 7179.947265625\n",
      "Iteration 404 of 410 with a loss of: 9169.564453125\n",
      "Iteration 405 of 410 with a loss of: 6334.470703125\n",
      "Iteration 406 of 410 with a loss of: 6399.64306640625\n",
      "Iteration 407 of 410 with a loss of: 5845.78173828125\n",
      "Iteration 408 of 410 with a loss of: 7771.24609375\n",
      "Iteration 409 of 410 with a loss of: 6095.376953125\n",
      "Iteration 410 of 410 with a loss of: 8749.47265625\n"
     ]
    }
   ],
   "source": [
    "iteration_number = 0 \n",
    "for epoch in range(epochs):\n",
    "    for x_batch, y_batch in dl_train:\n",
    "        #on GPU\n",
    "        x_batch = x_batch.cuda()\n",
    "        y_batch = y_batch.cuda()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        y_pred = model(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iteration_number += 1\n",
    "        if iteration_number % print_loss_every_n_iterations == 0:\n",
    "            print(f'Iteration {iteration_number} of {total_iterations} with a loss of: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "20952bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain test predictions\n",
    "model.eval() #put model into eval mode (for dropout, batchnorm etc)\n",
    "\n",
    "#collect targets and predictions by iterating through the test loader\n",
    "preds=[]\n",
    "targs=[]\n",
    "for x_batch, y_batch in dl_test:\n",
    "    #GPU\n",
    "    #x_batch = x_batch.cuda()\n",
    "    \n",
    "    preds.append(model(x_batch).detach().cpu().numpy())\n",
    "    targs.append(y_batch.numpy())\n",
    "    \n",
    "preds = np.concatenate(preds,axis=0)\n",
    "targs = np.concatenate(targs,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "996d02d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate some metric based on preds and targs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "1cd52e3fcb9baaa40b3d605a6296e70b2d59f0509251b8daccec7a45dc12b452"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
