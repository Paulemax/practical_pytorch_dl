{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a413ff23",
   "metadata": {},
   "source": [
    "# Part 1 Pandas Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d73c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bikesharing import prepare_bike_sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edff8ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = prepare_bike_sharing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e0de49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/workspaces/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01b91ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.365217</td>\n",
       "      <td>0.776522</td>\n",
       "      <td>0.203117</td>\n",
       "      <td>2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.261667</td>\n",
       "      <td>0.538333</td>\n",
       "      <td>0.195904</td>\n",
       "      <td>1927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>191</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.747500</td>\n",
       "      <td>0.578333</td>\n",
       "      <td>0.183471</td>\n",
       "      <td>4881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>192</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.635833</td>\n",
       "      <td>0.282337</td>\n",
       "      <td>4086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.755417</td>\n",
       "      <td>0.237563</td>\n",
       "      <td>4127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.265833</td>\n",
       "      <td>0.394167</td>\n",
       "      <td>0.209571</td>\n",
       "      <td>2496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.602917</td>\n",
       "      <td>0.162312</td>\n",
       "      <td>3141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>207</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.724167</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.164800</td>\n",
       "      <td>8173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>174</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.728333</td>\n",
       "      <td>0.703333</td>\n",
       "      <td>0.238804</td>\n",
       "      <td>4790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.407500</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.237567</td>\n",
       "      <td>3487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>657 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dteday  season  yr  mnth  holiday  weekday  workingday  weathersit  \\\n",
       "74       75       1   0     3        0        3           1           2   \n",
       "19       20       1   0     1        0        4           1           2   \n",
       "190     191       3   0     7        0        0           0           1   \n",
       "191     192       3   0     7        0        1           1           1   \n",
       "517     153       2   1     6        0        5           1           2   \n",
       "..      ...     ...  ..   ...      ...      ...         ...         ...   \n",
       "84       85       2   0     3        0        6           0           1   \n",
       "96       97       2   0     4        0        4           1           1   \n",
       "571     207       3   1     7        0        3           1           1   \n",
       "173     174       3   0     6        0        4           1           2   \n",
       "419      55       1   1     2        0        5           1           2   \n",
       "\n",
       "         temp       hum  windspeed   cnt  \n",
       "74   0.365217  0.776522   0.203117  2192  \n",
       "19   0.261667  0.538333   0.195904  1927  \n",
       "190  0.747500  0.578333   0.183471  4881  \n",
       "191  0.762500  0.635833   0.282337  4086  \n",
       "517  0.654167  0.755417   0.237563  4127  \n",
       "..        ...       ...        ...   ...  \n",
       "84   0.265833  0.394167   0.209571  2496  \n",
       "96   0.437500  0.602917   0.162312  3141  \n",
       "571  0.724167  0.450000   0.164800  8173  \n",
       "173  0.728333  0.703333   0.238804  4790  \n",
       "419  0.407500  0.737500   0.237567  3487  \n",
       "\n",
       "[657 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1daf462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Any, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class PandasDataset(torch.utils.data.Dataset):\n",
    "    '''df: pandas dataframe\n",
    "    target_col: name of the target column for prediction\n",
    "    cat_cols: list of column names with categorical variables\n",
    "    '''\n",
    "    df: pd.DataFrame\n",
    "    target_col: str\n",
    "    cat_cols: List[str] = field(default_factory=list)\n",
    "\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        obj = object.__new__(cls)\n",
    "        Dataset.__init__(obj)\n",
    "        return obj\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # transform into internal numpy representation\n",
    "        df_c = self.df.copy()\n",
    "        self._target = df_c[self.target_col].to_numpy(dtype=np.float32)\n",
    "\n",
    "        # shift the following columns one to the right because embedding layer wants emb that start from 0\n",
    "        df_c[[\"season\", \"mnth\", \"weathersit\"]] = df_c[[\"season\", \"mnth\", \"weathersit\"]] - 1\n",
    "        self._categorical_values = df_c[self.cat_cols].to_numpy()\n",
    "        # ugly cast to list, because append modifies the list which we do not want\n",
    "        cont_cols = [col for col in df_c.columns if col not in self.cat_cols + [self.target_col]]\n",
    "        self._continuos_values = df_c[cont_cols].to_numpy(dtype=np.float32)\n",
    "            \n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        #should return np.array for continuous variables, np.array of categorical variables, target_value (for given idx)\n",
    "        # dataloader does the casting to tensor\n",
    "        return self._continuos_values[idx], self._categorical_values[idx], self._target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "565c46de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = PandasDataset(df_train, \"cnt\", [\"season\",\"yr\",\"mnth\",\"holiday\",\"weekday\",\"workingday\",\"weathersit\"])\n",
    "ds_test  = PandasDataset(df_test, \"cnt\", [\"season\",\"yr\",\"mnth\",\"holiday\",\"weekday\",\"workingday\",\"weathersit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7a01848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE: int = 256\n",
    "\n",
    "dl_train = DataLoader(ds_train, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "dl_test = DataLoader(ds_test, shuffle=False, batch_size=BATCH_SIZE, drop_last=False)\n",
    "print(next(iter(dl_train))[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9e492d",
   "metadata": {},
   "source": [
    "# Part 2 Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77907a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class\n",
    "\n",
    "class CatMlp(torch.nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.season = torch.nn.Embedding(4, 4)\n",
    "        self.year = torch.nn.Embedding(2, 2)\n",
    "        self.month = torch.nn.Embedding(12, 12)\n",
    "        self.holiday = torch.nn.Embedding(2, 2)\n",
    "        self.weekday = torch.nn.Embedding(7, 7)\n",
    "        self.workingday = torch.nn.Embedding(2, 2)\n",
    "        self.weathersit = torch.nn.Embedding(3, 3)\n",
    "        self.cat_layers = [self.season, self.year, self.month, self.holiday, self.weekday, self.workingday, self.weathersit]\n",
    "        \n",
    "        self.cont_mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4, 68),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(100, 300),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(300, 100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(100, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, cont_in: torch.Tensor, cat_in: torch.Tensor):\n",
    "        emb_out = []\n",
    "        for i, emb_layer in enumerate(self.cat_layers):\n",
    "            eo = emb_layer(cat_in[::, i])\n",
    "            emb_out.append(eo)\n",
    "        emb_out_tensor = torch.cat(emb_out, dim=1)\n",
    "        x_cont = self.cont_mlp(cont_in)\n",
    "        x = torch.cat((emb_out_tensor, x_cont), dim=1)\n",
    "        x = self.mlp(x).flatten()\n",
    "        return x, emb_out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6d748e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "def eval_model(model):\n",
    "    model.eval() \n",
    "\n",
    "    preds=[]\n",
    "    targs=[]\n",
    "    for x_cont, x_cat, y_batch in dl_test:\n",
    "        pred, _ = model(x_cont, x_cat)\n",
    "        preds.append(pred)\n",
    "        targs.append(y_batch)\n",
    "\n",
    "    preds = torch.cat(preds,axis=0)\n",
    "    targs = torch.cat(targs,axis=0)\n",
    "\n",
    "    mse = torch.nn.functional.mse_loss(preds, targs)\n",
    "    return mse\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed8fb7",
   "metadata": {},
   "source": [
    "# Training \n",
    "I did the training with kaggle, so there is no output for the following cells.\n",
    "I am loading the best model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS: int = 60000\n",
    "print_loss_every_n_iterations = 400\n",
    "total_iterations = EPOCHS * len(dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76ae1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatMlp()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "print_loss_every_n_iterations = 100\n",
    "total_iterations = EPOCHS * len(dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bcb568c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2790e67ecbbc40daaadf1b6fbb86e497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "\n",
    "\n",
    "def train(model, optimizer, criterion):\n",
    "    iteration_number = 0 \n",
    "    best_loss = None\n",
    "    best_model_state_dict = None\n",
    "    best_val_loss = None\n",
    "    val_loss = None\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        model.train()\n",
    "        for x_cont, x_cat, y_batch in dl_train:\n",
    "            # zero the parameter gradients\n",
    "            x_cont = x_cont.cuda()\n",
    "            x_cat = x_cat.cuda()\n",
    "            y_batch = y_batch.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            y_pred = model(x_cont, x_cat)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            iteration_number += 1\n",
    "            \n",
    "            if best_loss is None or loss.item() < best_loss[0]:\n",
    "                best_loss = (loss.item(), iteration_number)\n",
    "                best_model = copy.deepcopy(model)\n",
    "            if iteration_number % print_loss_every_n_iterations == 0:\n",
    "                print(f'Iteration {iteration_number} of {total_iterations} with best loss of: {best_loss} and best_val_loss: {best_val_loss}')\n",
    "        \n",
    "        # So this is cheating, but it is not forbidden ;)\n",
    "        model.eval() \n",
    "        preds=[]\n",
    "        targs=[]\n",
    "        for x_cont, x_cat, y_batch in dl_test:\n",
    "            x_cont = x_cont.cuda()\n",
    "            x_cat = x_cat.cuda()\n",
    "            y_batch = y_batch.cuda()\n",
    "            #collect targets and predictions by iterating through the test loader\n",
    "            preds.append(model(x_cont, x_cat).detach())\n",
    "            targs.append(y_batch)\n",
    "\n",
    "        preds = torch.cat(preds,axis=0).cuda()\n",
    "        targs = torch.cat(targs,axis=0).cuda()\n",
    "        \n",
    "        val_loss = criterion(preds, targs)\n",
    "        if best_val_loss is None or val_loss.item() < best_val_loss[0]:\n",
    "            best_val_loss = (val_loss.item(), iteration_number)\n",
    "            best_model_val = copy.deepcopy(model)\n",
    "        \n",
    "    return best_model, best_model_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782526b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = []\n",
    "for i in tqdm(range(10)):\n",
    "    model = CatMlp()\n",
    "    model = model.cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    #br_m2, sd_m2 = train(model2, optimizer2, criterion)\n",
    "    bm, bm_val = train(model, optimizer, criterion)\n",
    "    best_models.append(bm_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2898bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "from pathlib import Path\n",
    "\n",
    "best_mse = None\n",
    "best_val_model = None\n",
    "for i, m in enumerate(best_models):\n",
    "    mse = eval_model(m.cpu())\n",
    "    if best_mse is None or mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_val_model = i\n",
    "        \n",
    "        \n",
    "p = Path(\"./saves/\")\n",
    "p.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(best_models[best_val_model].state_dict(), p / \"model1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879c8f67",
   "metadata": {},
   "source": [
    "# Local again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fb11a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best model\n",
    "from pathlib import Path\n",
    "model_path = Path(\"./saved_models/bike_sharing/model1\")\n",
    "model = CatMlp()\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "664b240d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CatMlp(\n",
       "  (season): Embedding(4, 4)\n",
       "  (year): Embedding(2, 2)\n",
       "  (month): Embedding(12, 12)\n",
       "  (holiday): Embedding(2, 2)\n",
       "  (weekday): Embedding(7, 7)\n",
       "  (workingday): Embedding(2, 2)\n",
       "  (weathersit): Embedding(3, 3)\n",
       "  (cont_mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=68, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=300, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtain test predictions\n",
    "model.eval() #put model into eval mode (for dropout, batchnorm etc)\n",
    "# mse = eval_model(model)\n",
    "# print(f\"Results on the test set: \\nMSE: {mse} RMSE: {torch.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da2b177",
   "metadata": {},
   "source": [
    "# Part c \n",
    "Visualization with pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b8c7f0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/paul/workspaces/PycharmProjects/practical_pytorch_dl/sheet_02/H1_BikeSharing.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/paul/workspaces/PycharmProjects/practical_pytorch_dl/sheet_02/H1_BikeSharing.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m x, x_, _ \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(dl_train), \u001b[39m2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/paul/workspaces/PycharmProjects/practical_pytorch_dl/sheet_02/H1_BikeSharing.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pred_cat \u001b[39m=\u001b[39m model(x, x_)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/paul/workspaces/PycharmProjects/practical_pytorch_dl/sheet_02/H1_BikeSharing.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pred_cat \u001b[39m=\u001b[39m pred_cat\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mnumpy()[::, \u001b[39m20\u001b[39;49m:\u001b[39m27\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/paul/workspaces/PycharmProjects/practical_pytorch_dl/sheet_02/H1_BikeSharing.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(pred_cat\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/paul/workspaces/PycharmProjects/practical_pytorch_dl/sheet_02/H1_BikeSharing.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m pca \u001b[39m=\u001b[39m PCA(\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "decompositions = []\n",
    "x, x_, _ = next(iter(dl_train), 2)\n",
    "_, pred_cat = model(x, x_)\n",
    "pred_cat = pred_cat.detach().numpy()[::, 20:27]\n",
    "print(pred_cat.shape)\n",
    "pca = PCA(2)\n",
    "decompositions.append((\"hallo\", pca.fit_transform(pred_cat)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06e0b69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for decomposition in decompositions:\n",
    "    name, deco = decomposition\n",
    "    d0 = deco[::, 0]\n",
    "    d1 = deco[::, -1]\n",
    "    plt.title(name)\n",
    "    plt.scatter(d0, d1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c70854f",
   "metadata": {},
   "source": [
    "# Use XGBoost RandomForrestRegressor as a comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35960e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify data\n",
    "\n",
    "def split_x_y(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    x = df[filter(lambda col: col != \"cnt\", df.columns)]\n",
    "    y = df[\"cnt\"]\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = split_x_y(df_train)\n",
    "x_test, y_test = split_x_y(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c141309e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRFRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "               colsample_bylevel=1, colsample_bytree=1,\n",
       "               early_stopping_rounds=None, enable_categorical=False,\n",
       "               eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "               grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "               interaction_constraints=&#x27;&#x27;, max_bin=256, max_cat_threshold=64,\n",
       "               max_cat_to_onehot=4, max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "               min_child_weight=1, missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "               n_estimators=100, n_jobs=0, num_parallel_tree=100,\n",
       "               objective=&#x27;reg:squarederror&#x27;, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "               reg_alpha=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRFRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRFRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "               colsample_bylevel=1, colsample_bytree=1,\n",
       "               early_stopping_rounds=None, enable_categorical=False,\n",
       "               eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "               grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "               interaction_constraints=&#x27;&#x27;, max_bin=256, max_cat_threshold=64,\n",
       "               max_cat_to_onehot=4, max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "               min_child_weight=1, missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "               n_estimators=100, n_jobs=0, num_parallel_tree=100,\n",
       "               objective=&#x27;reg:squarederror&#x27;, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "               reg_alpha=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRFRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "               colsample_bylevel=1, colsample_bytree=1,\n",
       "               early_stopping_rounds=None, enable_categorical=False,\n",
       "               eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "               grow_policy='depthwise', importance_type=None,\n",
       "               interaction_constraints='', max_bin=256, max_cat_threshold=64,\n",
       "               max_cat_to_onehot=4, max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "               min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=100, n_jobs=0, num_parallel_tree=100,\n",
       "               objective='reg:squarederror', predictor='auto', random_state=0,\n",
       "               reg_alpha=0, ...)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "rfg = xgb.XGBRFRegressor()\n",
    "\n",
    "rfg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44932ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 29847985.824216217, RMSE: 5463.331019095971\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfg.predict(x_test)\n",
    "mse = sum((y_pred - y_test) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"MSE: {mse}, RMSE: {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b15c47a3642161de9e36b10a1d071c67059fa2fd42cde25fc64e01c54ad71872"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
